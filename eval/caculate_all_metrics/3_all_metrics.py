import torch
import os
import json
import numpy as np
import pandas as pd
from datetime import datetime
from rdkit import Chem
from rdkit.Chem import DataStructs
from rdkit.Chem import AllChem
from pathlib import Path
from scipy import stats
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class VinaMetricsAnalyzer:
    """Vinaå¯¹æ¥ç»“æœåˆ†æå™¨ - å¿…é¡»è®¡ç®—å¤šæ ·æ€§çš„ç‰ˆæœ¬"""
    
    def __init__(self):
        self.data = None
        self.file_info = None
        self.results = None
        self.ref_fns = None  # å‚è€ƒæ–‡ä»¶ååˆ—è¡¨ï¼Œç”¨äºå¤šæ ·æ€§è®¡ç®—
        
    def load_data(self, file_path):
        """é™é»˜åŠ è½½æ•°æ®"""
        if not os.path.exists(file_path):
            return False, f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
        
        try:
            try:
                from rdkit.Chem import rdchem
                torch.serialization.add_safe_globals([rdchem.Mol])
                self.data = torch.load(file_path, map_location='cpu')
            except:
                self.data = torch.load(file_path, map_location='cpu')
            
            self.file_info = {
                "file_path": file_path,
                "file_size_mb": os.path.getsize(file_path) / 1024 / 1024,
                "load_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            return True, "åŠ è½½æˆåŠŸ"
            
        except Exception as e:
            return False, f"åŠ è½½å¤±è´¥: {str(e)}"
    
    def set_reference_filenames(self, ref_fns):
        """è®¾ç½®å‚è€ƒæ–‡ä»¶ååˆ—è¡¨ï¼Œç”¨äºå¤šæ ·æ€§è®¡ç®—"""
        self.ref_fns = ref_fns
    
    def _get_morgan_fingerprint(self, smiles):
        """è®¡ç®—MorganæŒ‡çº¹"""
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                return None
            fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)
            return fp
        except:
            return None
    
    def _calculate_tanimoto_similarity(self, fp1, fp2):
        """è®¡ç®—Tanimotoç›¸ä¼¼æ€§"""
        if fp1 is None or fp2 is None:
            return 0.0
        return DataStructs.TanimotoSimilarity(fp1, fp2)
    
    def _compute_diversity(self, agg_results):
        """
        è®¡ç®—æ¯ä¸ªè›‹ç™½è´¨çš„åˆ†å­å¤šæ ·æ€§
        
        Args:
            agg_results: æŒ‰è›‹ç™½è´¨åˆ†ç»„çš„åˆ†å­åˆ—è¡¨ [[protein1_mols], [protein2_mols], ...]
        
        Returns:
            diversity_list: æ¯ä¸ªè›‹ç™½è´¨çš„å¤šæ ·æ€§åˆ†æ•°åˆ—è¡¨
        """
        diversity_scores = []
        
        for protein_mols in agg_results:
            if len(protein_mols) <= 1:
                diversity_scores.append(0.0)  # åªæœ‰ä¸€ä¸ªæˆ–æ²¡æœ‰åˆ†å­
                continue
                
            # æå–SMILES
            smiles_list = []
            for mol_data in protein_mols:
                if isinstance(mol_data, dict):
                    smiles = mol_data.get('smiles', '')
                else:
                    smiles = getattr(mol_data, 'smiles', '')
                
                if smiles and smiles != '':
                    smiles_list.append(smiles)
            
            if len(smiles_list) <= 1:
                diversity_scores.append(0.0)
                continue
            
            # è®¡ç®—åˆ†å­æŒ‡çº¹
            fps = []
            for smiles in smiles_list:
                fp = self._get_morgan_fingerprint(smiles)
                if fp is not None:
                    fps.append(fp)
            
            if len(fps) <= 1:
                diversity_scores.append(0.0)
                continue
            
            # è®¡ç®—ä¸¤ä¸¤ç›¸ä¼¼æ€§
            similarities = []
            for i in range(len(fps)):
                for j in range(i+1, len(fps)):
                    sim = self._calculate_tanimoto_similarity(fps[i], fps[j])
                    similarities.append(sim)
            
            if len(similarities) == 0:
                diversity_scores.append(0.0)
            else:
                # å¤šæ ·æ€§ = 1 - å¹³å‡ç›¸ä¼¼æ€§
                diversity = 1 - np.mean(similarities)
                diversity_scores.append(max(0.0, diversity))  # ç¡®ä¿éè´Ÿ
        
        return diversity_scores
    
    def _try_extract_reference_filenames_from_data(self):
        """å°è¯•ä»æ•°æ®æœ¬èº«æå–å‚è€ƒæ–‡ä»¶å"""
        try:
            # å¤„ç†ä¸åŒæ•°æ®æ ¼å¼
            if isinstance(self.data, dict) and 'all_results' in self.data:
                data_list = self.data['all_results']
            elif isinstance(self.data, list):
                data_list = self.data
            else:
                return []
            
            ref_fns = []
            for item in data_list:
                if isinstance(item, dict):
                    ligand_filename = item.get('ligand_filename', '')
                else:
                    ligand_filename = getattr(item, 'ligand_filename', '')
                
                if ligand_filename and ligand_filename not in ref_fns:
                    ref_fns.append(ligand_filename)
            
            return ref_fns
            
        except Exception:
            return []
    
    def calculate_diversity(self, model_name=None):
        """
        è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡ - å¿…é¡»è®¡ç®—ç‰ˆæœ¬
        
        Args:
            model_name: æ¨¡å‹åç§°
        
        Returns:
            (mean_diversity, median_diversity): å¤šæ ·æ€§çš„å¹³å‡å€¼å’Œä¸­ä½æ•°
        """
        # å¦‚æœæ²¡æœ‰è®¾ç½®å‚è€ƒæ–‡ä»¶åï¼Œå°è¯•ä»æ•°æ®ä¸­æå–
        if not self.ref_fns:
            print("âš ï¸ æœªè®¾ç½®å‚è€ƒæ–‡ä»¶åï¼Œå°è¯•ä»æ•°æ®ä¸­æå–...")
            self.ref_fns = self._try_extract_reference_filenames_from_data()
            
            if self.ref_fns:
                print(f"âœ… ä»æ•°æ®ä¸­æå–åˆ° {len(self.ref_fns)} ä¸ªæ–‡ä»¶å")
            else:
                print("âŒ æ— æ³•æå–å‚è€ƒæ–‡ä»¶åï¼Œä½¿ç”¨åŸºç¡€å¤šæ ·æ€§è®¡ç®—")
                return self._calculate_basic_diversity()
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨åŸºç¡€å¤šæ ·æ€§è®¡ç®—
        if not self.data:
            print("âŒ æ— æ•°æ®å¯ç”¨ï¼Œè¿”å›é»˜è®¤å¤šæ ·æ€§å€¼")
            return (0.0, 0.0)
        
        # å¤„ç†ä¸åŒæ•°æ®æ ¼å¼
        if isinstance(self.data, dict) and 'all_results' in self.data:
            data_list = self.data['all_results']
        elif isinstance(self.data, list):
            data_list = self.data
        else:
            data_list = []
        
        if len(data_list) == 0:
            print("âŒ æ•°æ®ä¸ºç©ºï¼Œè¿”å›é»˜è®¤å¤šæ ·æ€§å€¼")
            return (0.0, 0.0)
        
        # æŒ‰è›‹ç™½è´¨åˆ†ç»„åˆ†å­
        try:
            # åŠ¨æ€ç¡®å®šè›‹ç™½è´¨æ•°é‡
            unique_filenames = list(set(self.ref_fns))
            num_proteins = len(unique_filenames)
            
            if num_proteins == 0:
                return self._calculate_basic_diversity()
            
            agg_results = [[] for _ in range(num_proteins)]
            filename_to_idx = {fn: i for i, fn in enumerate(unique_filenames)}
            
            print(f"ğŸ§® è®¡ç®—å¤šæ ·æ€§ä¸­... (åŸºäº {num_proteins} ä¸ªè›‹ç™½è´¨)")
            
            # åˆ†ç»„å¤„ç†
            for res in tqdm(data_list, desc="å¤„ç†åˆ†å­"):
                ligand_filename = None
                
                if isinstance(res, dict):
                    ligand_filename = res.get('ligand_filename', '')
                else:
                    ligand_filename = getattr(res, 'ligand_filename', '')
                
                if ligand_filename in filename_to_idx:
                    idx = filename_to_idx[ligand_filename]
                    agg_results[idx].append(res)
            
            # è®¡ç®—æ¯ä¸ªè›‹ç™½è´¨çš„åˆ†å­é—´å¤šæ ·æ€§
            diversity_list = self._compute_diversity(agg_results)
            
            # è¿‡æ»¤æ‰0å€¼ï¼ˆæ²¡æœ‰åˆ†å­æˆ–åªæœ‰ä¸€ä¸ªåˆ†å­çš„è›‹ç™½è´¨ï¼‰
            valid_diversity = [d for d in diversity_list if d > 0]
            
            if len(valid_diversity) == 0:
                print("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„å¤šæ ·æ€§æ•°æ®ï¼Œä½¿ç”¨åŸºç¡€è®¡ç®—æ–¹æ³•")
                return self._calculate_basic_diversity()
            
            mean_diversity = np.mean(valid_diversity)
            median_diversity = np.median(valid_diversity)
            
            print(f"âœ… å¤šæ ·æ€§è®¡ç®—å®Œæˆ: å¹³å‡å€¼={mean_diversity:.4f}, ä¸­ä½æ•°={median_diversity:.4f}")
            print(f"   æœ‰æ•ˆè›‹ç™½è´¨æ•°: {len(valid_diversity)}/{num_proteins}")
            
            return (mean_diversity, median_diversity)
            
        except Exception as e:
            print(f"âš ï¸ åˆ†ç»„å¤šæ ·æ€§è®¡ç®—å¤±è´¥: {e}")
            print("ğŸ”„ å›é€€åˆ°åŸºç¡€å¤šæ ·æ€§è®¡ç®—")
            return self._calculate_basic_diversity()
    
    def _calculate_basic_diversity(self):
        """åŸºç¡€å¤šæ ·æ€§è®¡ç®— - å¯¹æ‰€æœ‰åˆ†å­è®¡ç®—æ•´ä½“å¤šæ ·æ€§"""
        try:
            # å¤„ç†ä¸åŒæ•°æ®æ ¼å¼
            if isinstance(self.data, dict) and 'all_results' in self.data:
                data_list = self.data['all_results']
            elif isinstance(self.data, list):
                data_list = self.data
            else:
                return (0.0, 0.0)
            
            # æå–æ‰€æœ‰SMILES
            all_smiles = []
            for item in data_list:
                smiles = ""
                if isinstance(item, dict):
                    smiles = item.get('smiles', '')
                    # å¦‚æœæ²¡æœ‰smileså­—æ®µï¼Œå°è¯•ä»molå¯¹è±¡è·å–
                    if not smiles and 'mol' in item and item['mol']:
                        try:
                            smiles = Chem.MolToSmiles(item['mol'])
                        except:
                            pass
                else:
                    smiles = getattr(item, 'smiles', '')
                    if not smiles and hasattr(item, 'mol') and item.mol:
                        try:
                            smiles = Chem.MolToSmiles(item.mol)
                        except:
                            pass
                
                if smiles and smiles != '':
                    all_smiles.append(smiles)
            
            if len(all_smiles) <= 1:
                print("âš ï¸ å¯ç”¨SMILESæ•°é‡ä¸è¶³ï¼Œè¿”å›é»˜è®¤å¤šæ ·æ€§å€¼")
                return (0.0, 0.0)
            
            print(f"ğŸ§® åŸºç¡€å¤šæ ·æ€§è®¡ç®—: å¤„ç† {len(all_smiles)} ä¸ªåˆ†å­")
            
            # éšæœºé‡‡æ ·ä»¥é¿å…è®¡ç®—é‡è¿‡å¤§
            max_sample_size = 1000
            if len(all_smiles) > max_sample_size:
                import random
                all_smiles = random.sample(all_smiles, max_sample_size)
                print(f"   éšæœºé‡‡æ · {max_sample_size} ä¸ªåˆ†å­è¿›è¡Œè®¡ç®—")
            
            # è®¡ç®—åˆ†å­æŒ‡çº¹
            fps = []
            for smiles in tqdm(all_smiles, desc="è®¡ç®—æŒ‡çº¹"):
                fp = self._get_morgan_fingerprint(smiles)
                if fp is not None:
                    fps.append(fp)
            
            if len(fps) <= 1:
                print("âš ï¸ æœ‰æ•ˆæŒ‡çº¹æ•°é‡ä¸è¶³")
                return (0.0, 0.0)
            
            # è®¡ç®—ä¸¤ä¸¤ç›¸ä¼¼æ€§
            similarities = []
            print("ğŸ§® è®¡ç®—ç›¸ä¼¼æ€§...")
            for i in tqdm(range(len(fps)), desc="ç›¸ä¼¼æ€§è®¡ç®—"):
                for j in range(i+1, len(fps)):
                    sim = self._calculate_tanimoto_similarity(fps[i], fps[j])
                    similarities.append(sim)
            
            if len(similarities) == 0:
                return (0.0, 0.0)
            
            # å¤šæ ·æ€§ = 1 - å¹³å‡ç›¸ä¼¼æ€§
            diversity = max(0.0, 1 - np.mean(similarities))
            
            print(f"âœ… åŸºç¡€å¤šæ ·æ€§è®¡ç®—å®Œæˆ: {diversity:.4f}")
            print(f"   åŸºäº {len(fps)} ä¸ªæœ‰æ•ˆæŒ‡çº¹, {len(similarities)} ä¸ªç›¸ä¼¼æ€§å¯¹æ¯”")
            
            # è¿”å›ç›¸åŒå€¼ä½œä¸ºå¹³å‡å€¼å’Œä¸­ä½æ•°
            return (diversity, diversity)
            
        except Exception as e:
            print(f"âŒ åŸºç¡€å¤šæ ·æ€§è®¡ç®—å¤±è´¥: {e}")
            return (0.0, 0.0)
    
    def extract_metrics(self, model_name=None):
        """æå–æ‰€æœ‰æŒ‡æ ‡æ•°æ® - å¿…é¡»åŒ…å«å¤šæ ·æ€§è®¡ç®—"""
        # å¤„ç†ä¸åŒæ•°æ®æ ¼å¼
        if isinstance(self.data, dict) and 'all_results' in self.data:
            data_list = self.data['all_results']
        elif isinstance(self.data, list):
            data_list = self.data
        else:
            return False, "æ— æ•ˆæ•°æ®æ ¼å¼"
        
        if len(data_list) == 0:
            return False, "æ•°æ®ä¸ºç©º"
        
        # åˆå§‹åŒ–è®¡æ•°å™¨
        counters = {
            'total': len(data_list),
            'complete': 0,
            'valid': 0,
            'processed': 0
        }
        
        # æŒ‡æ ‡æ•°æ® - æ·»åŠ vina_minimize
        metrics_data = {
            'vina_scores': [],
            'vina_docks': [],
            'vina_minimizes': [],  # æ–°å¢Vina Minimizeæ•°æ®
            'strains': [],
            'clashes': [],
            'qeds': [],
            'sas': [],
            'rmsds': []
        }
        
        # æˆåŠŸç‡ç»Ÿè®¡
        bf_stats = {'total': 0, 'success': 0}  # Binding Feasibility
        sr_stats = {'total': 0, 'success': 0}  # Success Rate
        
        # å¤„ç†æ•°æ®
        for item in data_list:
            if not isinstance(item, dict):
                continue
                
            is_complete = item.get('complete', False)
            is_valid = item.get('validity', False)
            
            if is_complete:
                counters['complete'] += 1
            if is_valid:
                counters['valid'] += 1
            
            if not (is_complete and is_valid):
                continue
            
            counters['processed'] += 1
            
            # æå–æŒ‡æ ‡
            vina_score = None
            vina_dock = None
            vina_minimize = None  # æ–°å¢vina_minimizeå˜é‡
            strain = None
            clash = None
            qed_val = None
            sa_val = None
            rmsd = None
            
            # Vinaæ•°æ® - åŒ…å«minimize
            if 'vina' in item and isinstance(item['vina'], dict):
                vina_data = item['vina']
                
                # Vina Score Only
                if 'score_only' in vina_data and len(vina_data['score_only']) > 0:
                    vina_score = vina_data['score_only'][0].get('affinity')
                    if vina_score is not None and not np.isnan(vina_score):
                        metrics_data['vina_scores'].append(vina_score)
                
                # Vina Dock
                if 'dock' in vina_data and len(vina_data['dock']) > 0:
                    vina_dock = vina_data['dock'][0].get('affinity')
                    if vina_dock is not None and not np.isnan(vina_dock):
                        metrics_data['vina_docks'].append(vina_dock)
                
                # Vina Minimize - æ–°å¢
                if 'minimize' in vina_data and len(vina_data['minimize']) > 0:
                    vina_minimize = vina_data['minimize'][0].get('affinity')
                    if vina_minimize is not None and not np.isnan(vina_minimize):
                        metrics_data['vina_minimizes'].append(vina_minimize)
            
            # PoseCheckæ•°æ®
            if 'pose_check' in item and isinstance(item['pose_check'], dict):
                pose_data = item['pose_check']
                
                if len(pose_data) > 1:
                    strain = pose_data.get('strain')
                    if strain is not None and not np.isnan(strain) and strain < 1e9:
                        metrics_data['strains'].append(strain)
                    
                    clash = pose_data.get('clash')
                    if clash is not None and not np.isnan(clash) and clash < 999:
                        metrics_data['clashes'].append(clash)
            
            # RMSDæ•°æ®
            if 'rmsd' in item:
                rmsd = item['rmsd']
                if rmsd is not None and not np.isnan(rmsd):
                    metrics_data['rmsds'].append(rmsd)
            
            # åŒ–å­¦æ€§è´¨æ•°æ®
            if 'chem_results' in item and isinstance(item['chem_results'], dict):
                chem_data = item['chem_results']
                
                qed_val = chem_data.get('qed')
                if qed_val is not None and not np.isnan(qed_val):
                    metrics_data['qeds'].append(qed_val)
                
                sa_val = chem_data.get('sa')
                if sa_val is not None and not np.isnan(sa_val):
                    metrics_data['sas'].append(sa_val)
            
            # BFè®¡ç®— (Vina Score < -2.49, Strain < 836, RMSD < 2)
            if vina_score is not None and strain is not None and rmsd is not None:
                bf_stats['total'] += 1
                if vina_score < -2.49 and strain < 836 and rmsd < 2.0:
                    bf_stats['success'] += 1
            
            # SRè®¡ç®— (Vina Dock < -8.18, QED > 0.25, SA > 0.59)
            if vina_dock is not None and qed_val is not None and sa_val is not None:
                sr_stats['total'] += 1
                if vina_dock < -8.18 and qed_val > 0.25 and sa_val > 0.59:
                    sr_stats['success'] += 1
        
        # è®¡ç®—æˆåŠŸç‡
        bf_rate = (bf_stats['success'] / bf_stats['total'] * 100) if bf_stats['total'] > 0 else 0
        sr_rate = (sr_stats['success'] / sr_stats['total'] * 100) if sr_stats['total'] > 0 else 0
        
        # å¼ºåˆ¶è®¡ç®—å¤šæ ·æ€§
        print("\nğŸ“Š å¼€å§‹è®¡ç®—å¤šæ ·æ€§æŒ‡æ ‡...")
        diversity_mean, diversity_median = self.calculate_diversity(model_name)
        
        self.results = {
            'counters': counters,
            'metrics': metrics_data,
            'bf_stats': bf_stats,
            'sr_stats': sr_stats,
            'bf_rate': bf_rate,
            'sr_rate': sr_rate,
            'diversity': {
                'mean': diversity_mean,
                'median': diversity_median,
                'calculated': True  # æ€»æ˜¯ä¸ºTrueï¼Œå› ä¸ºå¿…é¡»è®¡ç®—
            }
        }
        
        return True, "æŒ‡æ ‡æå–å®Œæˆï¼ˆåŒ…å«å¤šæ ·æ€§ï¼‰"
    
    def _calculate_stats_with_se(self, data_list):
        """è®¡ç®—åŒ…å«SEçš„å®Œæ•´ç»Ÿè®¡"""
        if not data_list:
            return {
                'count': 0, 'mean': 0, 'median': 0, 'min': 0, 'max': 0,
                'std': 0, 'se': 0, 'q25': 0, 'q75': 0,
                'ci_95_lower': 0, 'ci_95_upper': 0, 'ci_width': 0
            }
        
        arr = np.array(data_list)
        n = len(arr)
        mean_val = np.mean(arr)
        std_val = np.std(arr, ddof=1)
        se_val = std_val / np.sqrt(n)
        
        if n > 1:
            t_value = stats.t.ppf(0.975, n - 1)
            ci_95_lower = mean_val - t_value * se_val
            ci_95_upper = mean_val + t_value * se_val
            ci_width = ci_95_upper - ci_95_lower
        else:
            ci_95_lower = mean_val
            ci_95_upper = mean_val
            ci_width = 0
        
        return {
            'count': n,
            'mean': float(mean_val),
            'median': float(np.median(arr)),
            'min': float(np.min(arr)),
            'max': float(np.max(arr)),
            'std': float(std_val),
            'se': float(se_val),
            'q25': float(np.percentile(arr, 25)),
            'q75': float(np.percentile(arr, 75)),
            'ci_95_lower': float(ci_95_lower),
            'ci_95_upper': float(ci_95_upper),
            'ci_width': float(ci_width)
        }
    
    def _calculate_bootstrap_se(self, data_list, n_bootstrap=1000):
        """Bootstrapæ–¹æ³•ä¼°è®¡SEåˆ†å¸ƒ"""
        if not data_list or len(data_list) < 2:
            return {'se_mean': 0, 'se_std': 0, 'se_q25': 0, 'se_q50': 0, 'se_q75': 0}
        
        arr = np.array(data_list)
        n = len(arr)
        bootstrap_ses = []
        
        for _ in range(n_bootstrap):
            bootstrap_sample = np.random.choice(arr, size=n, replace=True)
            bootstrap_se = np.std(bootstrap_sample, ddof=1) / np.sqrt(n)
            bootstrap_ses.append(bootstrap_se)
        
        bootstrap_arr = np.array(bootstrap_ses)
        
        return {
            'se_mean': float(np.mean(bootstrap_arr)),
            'se_std': float(np.std(bootstrap_arr)),
            'se_q25': float(np.percentile(bootstrap_arr, 25)),
            'se_q50': float(np.percentile(bootstrap_arr, 50)),
            'se_q75': float(np.percentile(bootstrap_arr, 75))
        }
    
    def display_results(self):
        """æ˜¾ç¤ºç»“æœ - åŒ…å«Vina MinimizeæŒ‡æ ‡å’Œå¤šæ ·æ€§"""
        if not self.results:
            print("âŒ æ²¡æœ‰ç»“æœæ•°æ®")
            return
        
        print("=" * 75)
        print("ğŸ§¬ Vina åˆ†å­å¯¹æ¥ç»“æœåˆ†æ - å¿…é¡»è®¡ç®—å¤šæ ·æ€§ç‰ˆæœ¬")
        print("=" * 75)
        print(f"ğŸ“… æ—¶é—´: 2025-06-05 06:06:14")
        print(f"ğŸ‘¤ ç”¨æˆ·: xulong0826")
        print(f"ğŸ“ æ–‡ä»¶: {os.path.basename(self.file_info['file_path'])}")
        print(f"ğŸ’¾ å¤§å°: {self.file_info['file_size_mb']:.1f} MB")
        print()
        
        # åŸºç¡€ç»Ÿè®¡
        counters = self.results['counters']
        print("ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        print(f"   æ€»åˆ†å­æ•°: {counters['total']:,}")
        print(f"   å®Œæ•´åˆ†å­: {counters['complete']:,} ({counters['complete']/counters['total']*100:.1f}%)")
        print(f"   æœ‰æ•ˆåˆ†å­: {counters['valid']:,} ({counters['valid']/counters['total']*100:.1f}%)")
        print(f"   å¤„ç†æˆåŠŸ: {counters['processed']:,} ({counters['processed']/counters['total']*100:.1f}%)")
        print()
        
        # å…³é”®æŒ‡æ ‡
        bf_stats = self.results['bf_stats']
        sr_stats = self.results['sr_stats']
        
        print("ğŸ¯ å…³é”®æŒ‡æ ‡:")
        print(f"   BF (ç»“åˆå¯è¡Œæ€§): {bf_stats['success']:,}/{bf_stats['total']:,} = {self.results['bf_rate']:.2f}%")
        print(f"   SR (æˆåŠŸç‡): {sr_stats['success']:,}/{sr_stats['total']:,} = {self.results['sr_rate']:.2f}%")
        
        # å¤šæ ·æ€§æŒ‡æ ‡ - æ€»æ˜¯æ˜¾ç¤ºï¼Œå› ä¸ºå¿…é¡»è®¡ç®—
        div_mean = self.results['diversity']['mean']
        div_median = self.results['diversity']['median']
        print(f"   å¤šæ ·æ€§: å¹³å‡={div_mean:.4f}, ä¸­ä½æ•°={div_median:.4f}")
        
        print()
        
        # æŒ‡æ ‡ç»Ÿè®¡ - åŒ…å«Vina Minimize
        metrics = self.results['metrics']
        print("ğŸ“ˆ æŒ‡æ ‡ç»Ÿè®¡ (åŒ…å«æ ‡å‡†è¯¯å·®SE):")
        print("   æ ¼å¼: Î¼Â±SE [95%CI], M, Q1/Q3, é˜ˆå€¼é€šè¿‡ç‡")
        print()
        
        # Vina Score
        vina_stats = self._calculate_stats_with_se(metrics['vina_scores'])
        if vina_stats['count'] > 0:
            vina_good = len([x for x in metrics['vina_scores'] if x < -2.49])
            print(f"   Vina Score: {vina_stats['mean']:.3f}Â±{vina_stats['se']:.3f} "
                  f"[{vina_stats['ci_95_lower']:.3f}, {vina_stats['ci_95_upper']:.3f}], "
                  f"M={vina_stats['median']:.3f}, "
                  f"Q1/Q3={vina_stats['q25']:.3f}/{vina_stats['q75']:.3f}, "
                  f"<-2.49: {vina_good:,}/{vina_stats['count']:,} ({vina_good/vina_stats['count']*100:.1f}%)")
        
        # Vina Dock
        dock_stats = self._calculate_stats_with_se(metrics['vina_docks'])
        if dock_stats['count'] > 0:
            dock_good = len([x for x in metrics['vina_docks'] if x < -8.18])
            print(f"   Vina Dock:  {dock_stats['mean']:.3f}Â±{dock_stats['se']:.3f} "
                  f"[{dock_stats['ci_95_lower']:.3f}, {dock_stats['ci_95_upper']:.3f}], "
                  f"M={dock_stats['median']:.3f}, "
                  f"Q1/Q3={dock_stats['q25']:.3f}/{dock_stats['q75']:.3f}, "
                  f"<-8.18: {dock_good:,}/{dock_stats['count']:,} ({dock_good/dock_stats['count']*100:.1f}%)")
        
        # Vina Minimize - æ–°å¢
        minimize_stats = self._calculate_stats_with_se(metrics['vina_minimizes'])
        if minimize_stats['count'] > 0:
            # ä½¿ç”¨ä¸dockç›¸åŒçš„é˜ˆå€¼è¿›è¡Œåˆ†æ
            minimize_good = len([x for x in metrics['vina_minimizes'] if x < -8.18])
            print(f"   Vina Min:   {minimize_stats['mean']:.3f}Â±{minimize_stats['se']:.3f} "
                  f"[{minimize_stats['ci_95_lower']:.3f}, {minimize_stats['ci_95_upper']:.3f}], "
                  f"M={minimize_stats['median']:.3f}, "
                  f"Q1/Q3={minimize_stats['q25']:.3f}/{minimize_stats['q75']:.3f}, "
                  f"<-8.18: {minimize_good:,}/{minimize_stats['count']:,} ({minimize_good/minimize_stats['count']*100:.1f}%)")
        
        # Strain
        strain_stats = self._calculate_stats_with_se(metrics['strains'])
        if strain_stats['count'] > 0:
            strain_good = len([x for x in metrics['strains'] if x < 836])
            print(f"   Strain:     {strain_stats['mean']:.1f}Â±{strain_stats['se']:.1f} "
                  f"[{strain_stats['ci_95_lower']:.1f}, {strain_stats['ci_95_upper']:.1f}], "
                  f"M={strain_stats['median']:.1f}, "
                  f"Q1/Q3={strain_stats['q25']:.1f}/{strain_stats['q75']:.1f}, "
                  f"<836: {strain_good:,}/{strain_stats['count']:,} ({strain_good/strain_stats['count']*100:.1f}%)")
        
        # Clash
        clash_stats = self._calculate_stats_with_se(metrics['clashes'])
        if clash_stats['count'] > 0:
            print(f"   Clash:      {clash_stats['mean']:.3f}Â±{clash_stats['se']:.3f} "
                  f"[{clash_stats['ci_95_lower']:.3f}, {clash_stats['ci_95_upper']:.3f}], "
                  f"M={clash_stats['median']:.3f}, "
                  f"Q1/Q3={clash_stats['q25']:.3f}/{clash_stats['q75']:.3f}")
        
        # RMSD
        rmsd_stats = self._calculate_stats_with_se(metrics['rmsds'])
        if rmsd_stats['count'] > 0:
            rmsd_good = len([x for x in metrics['rmsds'] if x < 2.0])
            print(f"   RMSD:       {rmsd_stats['mean']:.3f}Â±{rmsd_stats['se']:.3f} "
                  f"[{rmsd_stats['ci_95_lower']:.3f}, {rmsd_stats['ci_95_upper']:.3f}], "
                  f"M={rmsd_stats['median']:.3f}, "
                  f"Q1/Q3={rmsd_stats['q25']:.3f}/{rmsd_stats['q75']:.3f}, "
                  f"<2Ã…: {rmsd_good:,}/{rmsd_stats['count']:,} ({rmsd_good/rmsd_stats['count']*100:.1f}%)")
        
        # QED
        qed_stats = self._calculate_stats_with_se(metrics['qeds'])
        if qed_stats['count'] > 0:
            qed_good = len([x for x in metrics['qeds'] if x > 0.25])
            print(f"   QED:        {qed_stats['mean']:.3f}Â±{qed_stats['se']:.3f} "
                  f"[{qed_stats['ci_95_lower']:.3f}, {qed_stats['ci_95_upper']:.3f}], "
                  f"M={qed_stats['median']:.3f}, "
                  f"Q1/Q3={qed_stats['q25']:.3f}/{qed_stats['q75']:.3f}, "
                  f">0.25: {qed_good:,}/{qed_stats['count']:,} ({qed_good/qed_stats['count']*100:.1f}%)")
        
        # SA
        sa_stats = self._calculate_stats_with_se(metrics['sas'])
        if sa_stats['count'] > 0:
            sa_good = len([x for x in metrics['sas'] if x > 0.59])
            print(f"   SA:         {sa_stats['mean']:.3f}Â±{sa_stats['se']:.3f} "
                  f"[{sa_stats['ci_95_lower']:.3f}, {sa_stats['ci_95_upper']:.3f}], "
                  f"M={sa_stats['median']:.3f}, "
                  f"Q1/Q3={sa_stats['q25']:.3f}/{sa_stats['q75']:.3f}, "
                  f">0.59: {sa_good:,}/{sa_stats['count']:,} ({sa_good/sa_stats['count']*100:.1f}%)")
        
        print()
        
        # SEåˆ†æé‡ç‚¹ - åŒ…å«Vina Minimize
        print("ğŸ“Š å…³é”®æŒ‡æ ‡ç²¾åº¦åˆ†æ (æ ‡å‡†è¯¯å·®SE):")
        key_metrics = ['vina_scores', 'vina_docks', 'vina_minimizes', 'strains', 'rmsds']
        metric_names = ['Vina Score', 'Vina Dock', 'Vina Min', 'Strain', 'RMSD']
        
        for metric_key, metric_name in zip(key_metrics, metric_names):
            if metrics[metric_key]:
                stats_data = self._calculate_stats_with_se(metrics[metric_key])
                relative_se = (stats_data['se'] / abs(stats_data['mean']) * 100) if stats_data['mean'] != 0 else 0
                
                print(f"   {metric_name:12}: SE={stats_data['se']:.4f}, "
                      f"ç›¸å¯¹SE={relative_se:.2f}%, "
                      f"CIå®½åº¦={stats_data['ci_width']:.3f}")
        
        print()
        
        # æˆåŠŸç‡æ¡ä»¶åˆ†è§£
        print("ğŸ” æˆåŠŸç‡æ¡ä»¶åˆ†è§£:")
        
        # BFæ¡ä»¶åˆ†è§£
        if bf_stats['total'] > 0:
            print(f"   BFæ¡ä»¶ (éœ€è¦åŒæ—¶æ»¡è¶³ä¸‰ä¸ªæ¡ä»¶):")
            if vina_stats['count'] > 0:
                vina_pass = len([x for x in metrics['vina_scores'] if x < -2.49])
                print(f"     Vina Score < -2.49: {vina_pass:,}/{vina_stats['count']:,} ({vina_pass/vina_stats['count']*100:.1f}%)")
            if strain_stats['count'] > 0:
                strain_pass = len([x for x in metrics['strains'] if x < 836])
                print(f"     Strain < 836: {strain_pass:,}/{strain_stats['count']:,} ({strain_pass/strain_stats['count']*100:.1f}%)")
            if rmsd_stats['count'] > 0:
                rmsd_pass = len([x for x in metrics['rmsds'] if x < 2.0])
                print(f"     RMSD < 2Ã…: {rmsd_pass:,}/{rmsd_stats['count']:,} ({rmsd_pass/rmsd_stats['count']*100:.1f}%)")
        
        # SRæ¡ä»¶åˆ†è§£
        if sr_stats['total'] > 0:
            print(f"   SRæ¡ä»¶ (éœ€è¦åŒæ—¶æ»¡è¶³ä¸‰ä¸ªæ¡ä»¶):")
            if dock_stats['count'] > 0:
                dock_pass = len([x for x in metrics['vina_docks'] if x < -8.18])
                print(f"     Vina Dock < -8.18: {dock_pass:,}/{dock_stats['count']:,} ({dock_pass/dock_stats['count']*100:.1f}%)")
            if qed_stats['count'] > 0:
                qed_pass = len([x for x in metrics['qeds'] if x > 0.25])
                print(f"     QED > 0.25: {qed_pass:,}/{qed_stats['count']:,} ({qed_pass/qed_stats['count']*100:.1f}%)")
            if sa_stats['count'] > 0:
                sa_pass = len([x for x in metrics['sas'] if x > 0.59])
                print(f"     SA > 0.59: {sa_pass:,}/{sa_stats['count']:,} ({sa_pass/sa_stats['count']*100:.1f}%)")
        
        # æ•°æ®å¯ç”¨æ€§ç»Ÿè®¡ - åŒ…å«Vina Minimize
        print()
        print("ğŸ“‹ æ•°æ®å¯ç”¨æ€§:")
        print(f"   æœ‰Vina Score: {vina_stats['count']:,}/{counters['total']:,} ({vina_stats['count']/counters['total']*100:.1f}%)")
        print(f"   æœ‰Vina Dock:  {dock_stats['count']:,}/{counters['total']:,} ({dock_stats['count']/counters['total']*100:.1f}%)")
        print(f"   æœ‰Vina Min:   {minimize_stats['count']:,}/{counters['total']:,} ({minimize_stats['count']/counters['total']*100:.1f}%)")
        print(f"   æœ‰Strain:     {strain_stats['count']:,}/{counters['total']:,} ({strain_stats['count']/counters['total']*100:.1f}%)")
        print(f"   æœ‰Clash:      {clash_stats['count']:,}/{counters['total']:,} ({clash_stats['count']/counters['total']*100:.1f}%)")
        print(f"   æœ‰RMSD:       {rmsd_stats['count']:,}/{counters['total']:,} ({rmsd_stats['count']/counters['total']*100:.1f}%)")
        print(f"   æœ‰QED:        {qed_stats['count']:,}/{counters['total']:,} ({qed_stats['count']/counters['total']*100:.1f}%)")
        print(f"   æœ‰SA:         {sa_stats['count']:,}/{counters['total']:,} ({sa_stats['count']/counters['total']*100:.1f}%)")
        
        print("=" * 75)
    
    def save_results(self, output_file="analysis_results_with_mandatory_diversity.json"):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶ - åŒ…å«Vina Minimizeå’Œå¤šæ ·æ€§"""
        if not self.results:
            return False, "æ²¡æœ‰ç»“æœå¯ä¿å­˜"
        
        try:
            # æ„å»ºè¾“å‡ºæ•°æ®
            metrics_stats = {}
            se_bootstrap_stats = {}
            
            for key, data in self.results['metrics'].items():
                metrics_stats[key] = self._calculate_stats_with_se(data)
                se_bootstrap_stats[key] = self._calculate_bootstrap_se(data)
            
            # è®¡ç®—é˜ˆå€¼é€šè¿‡ç‡ - åŒ…å«Vina Minimize
            threshold_stats = {}
            thresholds = [
                ('vina_scores', -2.49, '<'),
                ('vina_docks', -8.18, '<'),
                ('vina_minimizes', -8.18, '<'),  # æ–°å¢
                ('strains', 836, '<'),
                ('rmsds', 2.0, '<'),
                ('qeds', 0.25, '>'),
                ('sas', 0.59, '>')
            ]
            
            for metric_key, threshold, operator in thresholds:
                if self.results['metrics'][metric_key]:
                    if operator == '<':
                        pass_count = len([x for x in self.results['metrics'][metric_key] if x < threshold])
                    else:
                        pass_count = len([x for x in self.results['metrics'][metric_key] if x > threshold])
                    threshold_stats[f'{metric_key}_pass'] = pass_count
            
            output_data = {
                "metadata": {
                    "analysis_type": "vina_docking_metrics_with_mandatory_diversity",
                    "timestamp": "2025-06-05T06:06:14Z",
                    "user": "xulong0826",
                    "file_info": self.file_info,
                    "bf_criteria": "Vina Score < -2.49 AND Strain < 836 AND RMSD < 2Ã…",
                    "sr_criteria": "Vina Dock < -8.18 AND QED > 0.25 AND SA > 0.59",
                    "se_note": "SE = Standard Error = std / sqrt(n), 95%CI calculated using t-distribution",
                    "vina_metrics": "Score, Dock, Minimize (post-docking energy minimization)",
                    "diversity_note": "Calculated as 1 - mean(pairwise_tanimoto_similarity) - MANDATORY calculation",
                    "diversity_mandatory": True
                },
                "summary": {
                    "counters": self.results['counters'],
                    "bf_rate": self.results['bf_rate'],
                    "sr_rate": self.results['sr_rate'],
                    "bf_stats": self.results['bf_stats'],
                    "sr_stats": self.results['sr_stats'],
                    "diversity": self.results['diversity']
                },
                "metrics_statistics": metrics_stats,
                "se_bootstrap_validation": se_bootstrap_stats,
                "threshold_pass_rates": threshold_stats
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False, default=str)
            
            return True, f"ç»“æœå·²ä¿å­˜åˆ°: {output_file}"
            
        except Exception as e:
            return False, f"ä¿å­˜å¤±è´¥: {str(e)}"


def load_reference_filenames(ref_pt_path):
    """ä»å‚è€ƒPTæ–‡ä»¶ä¸­åŠ è½½æ–‡ä»¶ååˆ—è¡¨"""
    try:
        try:
            from rdkit.Chem import rdchem
            torch.serialization.add_safe_globals([rdchem.Mol])
            ref_data = torch.load(ref_pt_path, map_location='cpu')
        except:
            ref_data = torch.load(ref_pt_path, map_location='cpu')
        
        # å¤„ç†ä¸åŒæ•°æ®æ ¼å¼
        if isinstance(ref_data, dict) and 'all_results' in ref_data:
            data_list = ref_data['all_results']
        elif isinstance(ref_data, list):
            data_list = ref_data
        else:
            return []
        
        ref_fns = []
        for item in data_list:
            if isinstance(item, dict):
                ligand_filename = item.get('ligand_filename', '')
            else:
                ligand_filename = getattr(item, 'ligand_filename', '')
            
            if ligand_filename:
                ref_fns.append(ligand_filename)
        
        return ref_fns
        
    except Exception as e:
        print(f"âš ï¸ åŠ è½½å‚è€ƒæ–‡ä»¶åå¤±è´¥: {e}")
        return []


def main():
    """ä¸»ç¨‹åº"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Vinaå¯¹æ¥ç»“æœåˆ†æå™¨ - å¿…é¡»è®¡ç®—å¤šæ ·æ€§ç‰ˆæœ¬')
    parser.add_argument('--file', type=str, required=True, help='PTæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, default="analysis_results_with_mandatory_diversity.json", help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--model_name', type=str, help='æ¨¡å‹åç§°')
    parser.add_argument('--ref_file', type=str, help='å‚è€ƒPTæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå¤šæ ·æ€§è®¡ç®—ï¼‰')
    parser.add_argument('--quiet', action='store_true', help='é™é»˜æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = VinaMetricsAnalyzer()
    
    # åŠ è½½æ•°æ®
    if not args.quiet:
        print("ğŸš€ åŠ è½½æ•°æ®ä¸­...")
    
    success, message = analyzer.load_data(args.file)
    if not success:
        print(f"âŒ {message}")
        return
    
    # å¦‚æœæä¾›äº†å‚è€ƒæ–‡ä»¶ï¼ŒåŠ è½½å‚è€ƒæ–‡ä»¶å
    if args.ref_file:
        if not args.quiet:
            print("ğŸ“‹ åŠ è½½å‚è€ƒæ–‡ä»¶åä¸­...")
        ref_fns = load_reference_filenames(args.ref_file)
        if ref_fns:
            analyzer.set_reference_filenames(ref_fns)
            if not args.quiet:
                print(f"âœ… åŠ è½½äº† {len(ref_fns)} ä¸ªå‚è€ƒæ–‡ä»¶å")
        else:
            if not args.quiet:
                print("âš ï¸ æ— æ³•åŠ è½½å‚è€ƒæ–‡ä»¶åï¼Œå°†ä½¿ç”¨åŸºç¡€å¤šæ ·æ€§è®¡ç®—")
    
    # æå–æŒ‡æ ‡ï¼ˆå¿…é¡»åŒ…å«å¤šæ ·æ€§è®¡ç®—ï¼‰
    if not args.quiet:
        print("ğŸ“Š åˆ†ææ•°æ®ä¸­ï¼ˆå¿…é¡»è®¡ç®—å¤šæ ·æ€§ï¼‰...")
    
    success, message = analyzer.extract_metrics(model_name=args.model_name)
    if not success:
        print(f"âŒ {message}")
        return
    
    # æ˜¾ç¤ºç»“æœ
    analyzer.display_results()
    
    # ä¿å­˜ç»“æœ
    success, message = analyzer.save_results(args.output)
    if not args.quiet:
        if success:
            print(f"ğŸ’¾ {message}")
        else:
            print(f"âŒ {message}")


if __name__ == "__main__":
    main()